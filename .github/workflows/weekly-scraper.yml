name: Biweekly PDF Scraper

on:
  schedule:
    # 每周一 08:00 UTC，但只在偶数周运行（0 表示周日，1 表示周一）
    - cron: '0 8 * * 1/2'  # 每两周的周一运行
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Create PDFs directory if not exists
        run: mkdir -p pdfs

      - name: Run scraper
        run: python scraper.py

      - name: Configure Git
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Commit and push downloaded PDFs
        run: |
          git add pdfs/*.pdf || echo "No new PDFs to add"
          git commit -m "Add new PDFs from biweekly scraper run" || echo "Nothing to commit"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}